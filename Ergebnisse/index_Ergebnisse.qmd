---
title: "Ergebnisse & Statistik"
execute:
  message: false
  echo: false
  warning: false
  error: false
  
bibliography: references.bib
lang: de
number-sections: false  
jupyter: false
engine: knitr
---
  
```{css}
#| echo: false
p {
  text-align: justify
}
```

Im den folgenden Unterkapiteln werden die Ergebnisse der durchgeführten Untersuchungen dargestellt. Die Gliederung erfolgt nach Eingangsuntersuchungen, physiologischen Belastungs- und Nachbelastungsparametern, ergometrischen Belastungsparametern sowie Wirkungsgrad- und Stoffwechselparametern.<br>
Im Kapitel "Wirkungsgrad- und Stoffwechselparameter" werden die inferenzstatistischen Analysen zur Hypothesenprüfung durchgeführt, in den anderen erfolgt die Darstellung der Ergebnisse rein deskriptiv. Diese systematische Aufbereitung der Daten soll eine übersichtliche und nachvollziehbare Präsentation der Untersuchungsergebnisse gewährleisten.

## Deskriptive Statistik

Die erhobenen Daten wurden für die deskriptive Analyse systematisch aufbereitet. Die initiale Datenverarbeitung erfolgte in Microsoft Excel, die weiterführende Analyse und Visualisierung wurde mit R (Version 4.4.2) durchgeführt. Die Darstellung der Ergebnisse erfolgte sowohl in Grafiken und Tabellen als auch in interaktiven Shiny-Applikationen.<br>
Zur Charakterisierung der Verteilungen wurden zentrale Tendenzen (arithmetisches Mittel, Median) sowie Streuungsmaße (Standardabweichung, Minimal- und Maximalwerte) berechnet. Die resultierenden statistischen Kennwerte wurden in Tabellen, Grafiken und interaktiven Visualisierungen zusammengefasst. Diese deskriptive Aufbereitung ermöglichte die Identifikation von Ausreißern und Verteilungsmustern und bildete die Grundlage für die weiterführenden Analysen.

## Inferenzstatistik

Die statistischen Analysen wurden mit R (Version 4.2.1) durchgeführt. Als Grundlage für die Wahl der statistischen Verfahren wurden die Daten zunächst mittels Shapiro-Wilk-Test auf Normalverteilung und mittels Levene-Test auf Varianzhomogenität geprüft.<br>
Bei erfüllten Voraussetzungen (Normalverteilung und Varianzhomogenität) kamen parametrische Verfahren zum Einsatz. Hierfür wurden einfaktorielle Varianzanalysen (ANOVA) mit Messwiederholung und anschließenden Tukey HSD Post-hoc Tests durchgeführt. Bei verletzten Voraussetzungen wurden nicht-parametrische Verfahren angewandt. Der Friedman-Test mit nachfolgenden paarweisen Wilcoxon-Tests (Bonferroni-korrigiert) für Mehrfachvergleiche und der Wilcoxon-Test für Einzelvergleiche zwischen zwei Bedingungen.<br>
Für die Analyse von Zusammenhängen wurden lineare und nicht-lineare Regressionsmodelle verwendet. Bei linearen Zusammenhängen wurde die Methode der kleinsten Quadrate angewandt (lm()-Funktion). Die statistische Signifikanz wurde mittels F-Test der Varianzanalyse überprüft. Die Modellgüte wurde durch das Bestimmtheitsmaß (R^2^) quantifiziert. Bei nicht-linearen Zusammenhängen wurden die Modellparameter durch einen iterativen Levenberg-Marquardt-Optimierungsalgorithmus geschätzt (nlsLM()-Funktion). Die Modellgüte wurde ebenfalls durch das Bestimmtheitsmaß (R^2^) quantifiziert. Die Startwerte der Regressionsmodelle wurden basierend auf theoretischen Überlegungen gewählt.

Für alle statistischen Analysen wurde ein Signifikanzniveau von α = 0.05 verwendet. Die Ergebnisse wurden anhand ihrer p-Werte als statistisch hoch signifikant (p ≤ 0.01), signifikant (p ≤ 0.05) oder nicht signifikant (p > 0.05) klassifiziert. Zusätzlich wurden statistische Trends im Bereich 0.05 < p < 0.1 dokumentiert. In den Diagrammen erfolgte die Darstellung der Signifikanzniveaus mittels Asterisken (*** p < 0.001; ** p < 0.01; * p < 0.05), während signifikante Haupteffekte durch ein Kreuz (†) gekennzeichnet wurden.<br>
Die Effektstärken wurden mittels partiellem Eta-Quadrat (η~p~^2^) für parametrische Tests quantifiziert, wobei Werte ≥ 0.01 als kleiner, ≥ 0.06 als mittlerer und ≥ 0.14 als großer Effekt interpretiert wurden [@Cohen1988, 368]. Für Wilcoxon-Tests wurde die Effektstärke r bestimmt, mit Werten ≥ 0.1 als kleiner, ≥ 0.3 als mittlerer und ≥ 0.5 als großer Effekt. Die gleichen Grenzwerte wurden für den Pearson Korrelationskoeffizienten r verwendet, wobei Werte ≥ 0.1 als kleiner, ≥ 0.3 als mittlerer und ≥ 0.5 als großer Effekt interpretiert wurden. Bei Paarvergleichen wurde Cohens d als standardisierte Effektgröße berechnet, wobei Werte < 0.2 als trivialer, 0.2 ≤ d < 0.5 als kleiner, 0.5 ≤ d < 0.8 als mittlerer und d ≥ 0.8 als großer Effekt interpretiert wurden [@Cohen1992].

Zur Analyse von Zusammenhängen zwischen den erhobenen Parametern wurden verschiedene Regressionsanalysen durchgeführt. Lineare Zusammenhänge wurden mittels linearer Regressionsmodelle quantifiziert, nicht-lineare Beziehungen durch exponentielle Regressionsmodelle beschrieben. Die Modellgüte wurde jeweils durch das Bestimmtheitsmaß (R^2^) evaluiert, welches den Anteil der durch das Modell erklärten Varianz an der Gesamtvarianz beschreibt und somit eine quantitative Bewertung der funktionellen Zusammenhänge zwischen den untersuchten Parametern ermöglicht.





